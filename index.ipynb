{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ames.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n",
    "         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n",
    "         'GarageArea', 'Fireplaces', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81590682 0.78658346 0.77744573 0.77448228 0.63013673]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "base_model = LinearRegression()\n",
    "\n",
    "y = df[['SalePrice']]\n",
    "X = df.drop(columns = ['SalePrice'])\n",
    "X_scaled = pd.DataFrame(scale(X),columns = X.columns)\n",
    "\n",
    "## For MySelf\n",
    "print(cross_val_score(base_model, X_scaled, y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7524751004088885"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "crossval = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "base_model_scores = cross_val_score(base_model , X_scaled, y, scoring=\"r2\", \n",
    "                         cv = crossval)\n",
    "base_model_r2 = np.mean(base_model_scores)\n",
    "base_model_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From GitHub\n",
    "\n",
    "# y = df[['SalePrice']]\n",
    "# X = df.drop(columns='SalePrice')\n",
    "\n",
    "# X_scaled = scale(X)\n",
    "# X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# all_data = pd.concat([y, X_scaled], axis=1)\n",
    "# regression = LinearRegression()\n",
    "\n",
    "# crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# baseline = np.mean(cross_val_score(regression, X_scaled, y, scoring='r2',\n",
    "#            cv=crossvalidation))\n",
    "# baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "\n",
    "combo = list(combinations(X_scaled.columns,2))\n",
    "X_inter = X_scaled.copy()\n",
    "\n",
    "combo_r2 = pd.DataFrame()\n",
    "for i,item in enumerate(combo):\n",
    "    \n",
    "    X_inter[\"interactions\"] = X_scaled[item[0]]*X_scaled[item[1]]\n",
    "    inter_model_r2 = np.mean(cross_val_score(base_model, X_inter, y, \n",
    "                                                scoring=\"r2\", cv = crossval))\n",
    "    \n",
    "#     combo_r2.loc[i, \"combo\"] = item[0] + \"*\" + item[1]\n",
    "    combo_r2.loc[i, \"r2\"] = np.round(inter_model_r2,3)\n",
    "    if inter_model_r2 > base_model_r2:\n",
    "        combo_r2.loc[i, \"r2\"] = np.round(inter_model_r2,3)\n",
    "        combo_r2.loc[i, \"col_1\"] = item[0]\n",
    "        combo_r2.loc[i, \"col_2\"] = item[1]\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\", where var1 and var2 are the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770</td>\n",
       "      <td>OverallQual</td>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764</td>\n",
       "      <td>OverallQual</td>\n",
       "      <td>GarageArea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.758</td>\n",
       "      <td>OverallQual</td>\n",
       "      <td>2ndFlrSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.756</td>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>GrLivArea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756</td>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.754</td>\n",
       "      <td>OverallQual</td>\n",
       "      <td>Fireplaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.754</td>\n",
       "      <td>OverallCond</td>\n",
       "      <td>TotalBsmtSF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      r2        col_1         col_2\n",
       "0  0.770  OverallQual  TotRmsAbvGrd\n",
       "1  0.764  OverallQual    GarageArea\n",
       "2  0.758  OverallQual      2ndFlrSF\n",
       "3  0.756     2ndFlrSF     GrLivArea\n",
       "4  0.756     2ndFlrSF  TotRmsAbvGrd\n",
       "5  0.754  OverallQual    Fireplaces\n",
       "6  0.754  OverallCond   TotalBsmtSF"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "best_inter_score = combo_r2.loc[combo_r2[\"r2\"]>base_model_r2].sort_values(\n",
    "                                            by = \"r2\", ascending = False\n",
    "                                                                     )\n",
    "\n",
    "best_inter = best_inter_score.iloc[0:7]\n",
    "best_inter.reset_index(inplace = True, drop = True)\n",
    "best_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF', '1stFlrSF',\n",
       "       '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd', 'GarageArea', 'Fireplaces',\n",
       "       'OverallQual_TotRmsAbvGrd', 'OverallQual_GarageArea',\n",
       "       'OverallQual_2ndFlrSF', '2ndFlrSF_GrLivArea', '2ndFlrSF_TotRmsAbvGrd',\n",
       "       'OverallQual_Fireplaces', 'OverallCond_TotalBsmtSF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter = X_scaled.copy()\n",
    "for i in range(len(best_inter)):\n",
    "    col1 = best_inter.loc[int(i), \"col_1\"]\n",
    "    col2 = best_inter.loc[int(i), \"col_2\"]\n",
    "    df_inter[col1+\"_\"+col2] = df_inter[col1]*df_inter[col2]\n",
    "df_inter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('OverallQual', 'TotRmsAbvGrd', 0.77), ('OverallQual', 'GarageArea', 0.764), ('OverallQual', '2ndFlrSF', 0.758), ('2ndFlrSF', 'GrLivArea', 0.756), ('2ndFlrSF', 'TotRmsAbvGrd', 0.756), ('OverallQual', 'Fireplaces', 0.754), ('OverallCond', 'TotalBsmtSF', 0.754)]\n"
     ]
    }
   ],
   "source": [
    "### From GitHub\n",
    "from itertools import combinations\n",
    "X = df.drop(columns = ['SalePrice'])\n",
    "combo = list(combinations(X.columns, 2))\n",
    "baseline = base_model_r2\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combo:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(base_model, data, y, scoring='r2', cv=crossval))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score, 3)))\n",
    "            \n",
    "print('Top 7 interactions: %s' %sorted(interactions, \n",
    "                                       key=lambda inter: inter[2], \n",
    "                                       reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "degree = [2, 3, 4]\n",
    "poly_r2 = pd.DataFrame()\n",
    "i = 0\n",
    "for col in X_scaled.columns:\n",
    "    \n",
    "    for item in degree:\n",
    "        \n",
    "        X_poly = X_scaled.copy()\n",
    "        \n",
    "        poly = PolynomialFeatures(degree=item, \n",
    "                          interaction_only=False, \n",
    "                          include_bias=False)\n",
    "        X_col = poly.fit_transform(X_scaled[[col]])\n",
    "        \n",
    "        X_poly.drop(columns = col, axis = 1, inplace = True)\n",
    "        X_poly_f = pd.concat([X_poly, pd.DataFrame(X_col)], axis = 1)\n",
    "        \n",
    "        ploy_model_r2 = np.mean(cross_val_score(base_model, X_poly_f, y, \n",
    "                                                scoring=\"r2\", cv = crossval))\n",
    "        \n",
    "        poly_r2.loc[i, \"col\"] = col\n",
    "        poly_r2.loc[i, \"degree\"] = item\n",
    "        poly_r2.loc[i, \"r2\"] = np.round(ploy_model_r2,3)\n",
    "        \n",
    "        i += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_score = poly_r2.loc[poly_r2[\"r2\"]>base_model_r2].sort_values(\n",
    "                                            by = \"r2\", ascending = False\n",
    "                                                                     )\n",
    "\n",
    "top_7_poly = better_score.iloc[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum $R^2$ possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "best_poly = better_score.groupby([\"col\"])[\"degree\",\"r2\"].max().sort_values(\n",
    "    by = \"r2\",\n",
    "    ascending = False)\n",
    "\n",
    "best_poly.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>degree</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            col  degree     r2\n",
       "0     GrLivArea     4.0  0.807\n",
       "1   OverallQual     4.0  0.781\n",
       "2      2ndFlrSF     4.0  0.775\n",
       "3    GarageArea     4.0  0.767\n",
       "4   OverallCond     4.0  0.753\n",
       "5  TotRmsAbvGrd     3.0  0.753"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('GrLivArea', 4, 0.807), ('GrLivArea', 3, 0.788), ('OverallQual', 2, 0.781), ('OverallQual', 3, 0.779), ('OverallQual', 4, 0.779), ('2ndFlrSF', 3, 0.775), ('2ndFlrSF', 2, 0.771), ('2ndFlrSF', 4, 0.771), ('GarageArea', 4, 0.767), ('GarageArea', 3, 0.758)]\n"
     ]
    }
   ],
   "source": [
    "### From GitHub\n",
    "\n",
    "polynomials = []\n",
    "for col in X.columns:\n",
    "    for degree in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X_transformed = poly.fit_transform(X[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X_transformed)], axis=1)\n",
    "        score = np.mean(cross_val_score(base_model, data, y, \n",
    "                                        scoring='r2', cv=crossval))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score, 3)))\n",
    "print('Top 10 polynomials: %s' %sorted(polynomials, key=lambda poly: poly[2], \n",
    "                                       reverse=True)[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "OverallQual     0.781\n",
       "OverallCond     0.753\n",
       "2ndFlrSF        0.775\n",
       "GrLivArea       0.807\n",
       "TotRmsAbvGrd    0.753\n",
       "GarageArea      0.767\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### From GitHub\n",
    "\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best $R^2$ compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# features_to_pick = list(best_poly.iloc[0:2,0])\n",
    "# degree_to_pick  = list(best_poly.iloc[0:2,1])\n",
    "# feature_degree = list(zip(features_to_pick, degree_to_pick))\n",
    "\n",
    "# # X_features = X_scaled.copy()\n",
    "# # X_poly_final = X_scaled.drop(columns = features_to_pick, axis = 1)\n",
    "\n",
    "# for (col, deg) in feature_degree:\n",
    "\n",
    "#     poly = PolynomialFeatures(degree = int(deg), \n",
    "#                           interaction_only=False, \n",
    "#                           include_bias=False)\n",
    "\n",
    "#     X_features = poly.fit_transform(X[[col]])\n",
    "#     col_names = [col + f\"**{i}\" for i in range(int(deg))]\n",
    "#     X_poly = pd.DataFrame(X_features, columns = col_names)\n",
    "    \n",
    "#     df_inter = pd.concat([df_inter.drop(col,axis = 1), pd.DataFrame(X_features, columns = col_names)], axis = 1)\n",
    "\n",
    "## From GitHub\n",
    "\n",
    "for col in ['OverallQual', 'GrLivArea']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(X_transformed, columns=colnames)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>OverallQual_TotRmsAbvGrd</th>\n",
       "      <th>OverallQual_GarageArea</th>\n",
       "      <th>...</th>\n",
       "      <th>OverallQual_Fireplaces</th>\n",
       "      <th>OverallCond_TotalBsmtSF</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallQual_2</th>\n",
       "      <th>OverallQual_3</th>\n",
       "      <th>OverallQual_4</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GrLivArea_2</th>\n",
       "      <th>GrLivArea_3</th>\n",
       "      <th>GrLivArea_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.459303</td>\n",
       "      <td>-0.793434</td>\n",
       "      <td>1.161852</td>\n",
       "      <td>0.912210</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>0.228669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619704</td>\n",
       "      <td>0.237551</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2924100.0</td>\n",
       "      <td>5.000211e+09</td>\n",
       "      <td>8.550361e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>0.466465</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>-0.795163</td>\n",
       "      <td>-0.318683</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.022893</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043137</td>\n",
       "      <td>1.016720</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1592644.0</td>\n",
       "      <td>2.009917e+09</td>\n",
       "      <td>2.536515e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073480</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.313369</td>\n",
       "      <td>-0.627826</td>\n",
       "      <td>1.189351</td>\n",
       "      <td>-0.318683</td>\n",
       "      <td>0.631726</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>-0.207616</td>\n",
       "      <td>0.411557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.162074</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>3189796.0</td>\n",
       "      <td>5.696976e+09</td>\n",
       "      <td>1.017480e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.096897</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.687324</td>\n",
       "      <td>-0.521734</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.296763</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.193335</td>\n",
       "      <td>0.515193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.355484</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>2948089.0</td>\n",
       "      <td>5.061869e+09</td>\n",
       "      <td>8.691229e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375148</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>1.617877</td>\n",
       "      <td>1.527656</td>\n",
       "      <td>1.698485</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>2.100214</td>\n",
       "      <td>2.335068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825557</td>\n",
       "      <td>-0.103274</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>4831204.0</td>\n",
       "      <td>1.061899e+10</td>\n",
       "      <td>2.334053e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  TotRmsAbvGrd  \\\n",
       "0 -0.207142    -0.517200    -0.459303 -0.793434  1.161852      0.912210   \n",
       "1 -0.091886     2.179628     0.466465  0.257140 -0.795163     -0.318683   \n",
       "2  0.073480    -0.517200    -0.313369 -0.627826  1.189351     -0.318683   \n",
       "3 -0.096897    -0.517200    -0.687324 -0.521734  0.937276      0.296763   \n",
       "4  0.375148    -0.517200     0.199680 -0.045611  1.617877      1.527656   \n",
       "\n",
       "   GarageArea  Fireplaces  OverallQual_TotRmsAbvGrd  OverallQual_GarageArea  \\\n",
       "0    0.351000   -0.951226                  0.594286                0.228669   \n",
       "1   -0.060731    0.600495                  0.022893                0.004363   \n",
       "2    0.631726    0.600495                 -0.207616                0.411557   \n",
       "3    0.790804    0.600495                  0.193335                0.515193   \n",
       "4    1.698485    0.600495                  2.100214                2.335068   \n",
       "\n",
       "   ...  OverallQual_Fireplaces  OverallCond_TotalBsmtSF  OverallQual  \\\n",
       "0  ...               -0.619704                 0.237551          7.0   \n",
       "1  ...               -0.043137                 1.016720          6.0   \n",
       "2  ...                0.391210                 0.162074          7.0   \n",
       "3  ...                0.391210                 0.355484          7.0   \n",
       "4  ...                0.825557                -0.103274          8.0   \n",
       "\n",
       "   OverallQual_2  OverallQual_3  OverallQual_4  GrLivArea  GrLivArea_2  \\\n",
       "0           49.0          343.0         2401.0     1710.0    2924100.0   \n",
       "1           36.0          216.0         1296.0     1262.0    1592644.0   \n",
       "2           49.0          343.0         2401.0     1786.0    3189796.0   \n",
       "3           49.0          343.0         2401.0     1717.0    2948089.0   \n",
       "4           64.0          512.0         4096.0     2198.0    4831204.0   \n",
       "\n",
       "    GrLivArea_3   GrLivArea_4  \n",
       "0  5.000211e+09  8.550361e+12  \n",
       "1  2.009917e+09  2.536515e+12  \n",
       "2  5.696976e+09  1.017480e+13  \n",
       "3  5.061869e+09  8.691229e+12  \n",
       "4  1.061899e+10  2.334053e+13  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the $R^2$ of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245194818705173"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "ploy_final_model_r2 = np.mean(cross_val_score(base_model, \n",
    "                                              df_inter,\n",
    "                                              y, \n",
    "                                              scoring=\"r2\",\n",
    "                                              cv = crossval))\n",
    "ploy_final_model_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "\n",
    "### From GitHub\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare $R^2$ and RMSE using train-test split. Compare with the baseline model.\n",
    "\n",
    "Remember, you can find the Root Mean Squared Error (RMSE) by setting `squared=False` inside the function (see [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)), and the RMSE returns values that are in the same units as our target - so we can see how far off our predicted sale prices are in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-Squared: 0.7478270652928448\n",
      "Test R-Squared: 0.8120708166668685\n",
      "Training RMSE: 39424.15590381302\n",
      "Test RMSE: 35519.17035590487\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "y_train_predict = linreg_all.predict(X_train)\n",
    "\n",
    "# Print R-Squared and RMSE\n",
    "# print('Training R-Squared:', linreg_all.score(X_train, y_train))\n",
    "print('Training R-Squared:', linreg_all.score(X_train, y_train))\n",
    "print('Test R-Squared:', linreg_all.score(X_test, y_test))\n",
    "print('Training RMSE:', mean_squared_error(y_train, \n",
    "                                           linreg_all.predict(X_train), \n",
    "                                           squared=False))\n",
    "print('Test RMSE:', mean_squared_error(y_test, \n",
    "                                       linreg_all.predict(X_test), \n",
    "                                       squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-Squared: 0.8446321043844025\n",
      "Test R-Squared: 0.8652881796740386\n",
      "Training RMSE: 30945.23670210737\n",
      "Test RMSE: 30072.432048410283\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha = model_aic.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R-Squared and RMSE\n",
    "print('Training R-Squared:', lasso.score(X_train, y_train))\n",
    "print('Test R-Squared:', lasso.score(X_test, y_test))\n",
    "print('Training RMSE:', mean_squared_error(y_train, \n",
    "                                           lasso.predict(X_train), \n",
    "                                           squared=False))\n",
    "print('Test RMSE:', mean_squared_error(y_test, \n",
    "                                       lasso.predict(X_test), \n",
    "                                       squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-Squared: 0.8445833071362633\n",
      "Test R-Squared: 0.865202119898564\n",
      "Training RMSE: 30950.09589080876\n",
      "Test RMSE: 30082.036304145742\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha = model_bic.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R-Squared and RMSE\n",
    "print('Training R-Squared:', lasso.score(X_train, y_train))\n",
    "print('Test R-Squared:', lasso.score(X_test, y_test))\n",
    "print('Training RMSE:', mean_squared_error(y_train, \n",
    "                                           lasso.predict(X_train), \n",
    "                                           squared=False))\n",
    "print('Test RMSE:', mean_squared_error(y_test, \n",
    "                                       lasso.predict(X_test), \n",
    "                                       squared=False))\n",
    "\n",
    "\n",
    "# Print R-Squared and RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using Lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
